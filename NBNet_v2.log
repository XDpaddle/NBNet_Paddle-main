nohup: ignoring input
Disable distributed.
WARNING: OMP_NUM_THREADS set to 14, not 1. The computation speed will not be optimized if you use data parallel. It will fail if this PaddlePaddle binary is compiled with OpenBlas since OpenBlas does not support multi-threads.
PLEASE USE OMP_NUM_THREADS WISELY.
/root/miniconda3/lib/python3.8/site-packages/skimage/data/__init__.py:107: DeprecationWarning: 
    Importing file_hash from pooch.utils is DEPRECATED. Please import from the
    top-level namespace (`from pooch import file_hash`) instead, which is fully
    backwards compatible with pooch >= 0.1.
    
  return file_hash(path) == expected_hash
2023-06-09 23:01:26,043 INFO: 
  name: GaussianColorDenoising_NBNet
  model_type: ImageCleanModel
  scale: 1
  num_gpu: 1
  manual_seed: 100
  datasets:[
    train:[
      name: TrainSet
      type: Dataset_GaussianDenoising
      sigma_type: random
      sigma_range: [0, 50]
      in_ch: 3
      dataroot_gt: /root/autodl-tmp/SIDD/data/SIDD_patches/train/groundtruth
      dataroot_lq: none
      geometric_augs: True
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      use_shuffle: True
      num_worker_per_gpu: 4
      batch_size_per_gpu: 4
      mini_batch_sizes: [8, 5, 4, 2, 1, 1]
      iters: [184000, 128000, 96000, 72000, 72000, 48000]
      gt_size: 384
      gt_sizes: [128, 160, 192, 256, 320, 384]
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 1
    ]
    val:[
      name: ValSet
      type: Dataset_GaussianDenoising
      sigma_test: 15
      in_ch: 3
      dataroot_gt: /root/autodl-tmp/SIDD/data/SIDD_patches/val/groundtruth
      dataroot_lq: none
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: NBNet
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: None
    output: /root/autodl-tmp/Restormer_Paddle-main/exp/
    root: /root/autodl-tmp
    experiments_root: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet
    models: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/models
    training_states: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/training_states
    log: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet
    visualization: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/visualization
  ]
  train:[
    total_iter: 1000000
    warmup_iter: -1
    use_grad_clip: True
    scheduler:[
      type: CosineAnnealingRestartCyclicLR
      learning_rate: 0.00015
      periods: [184000, 416000]
      restart_weights: [1, 1]
      eta_mins: [0.00015, 1e-06]
    ]
    mixing_augs:[
      mixup: True
      mixup_beta: 1.2
      use_identity: True
    ]
    optim_g:[
      type: AdamW
      weight_decay: 0.0001
      beta1: 0.9
      beta2: 0.999
    ]
    pixel_opt:[
      type: L1Loss
      loss_weight: 1
      reduction: mean
    ]
  ]
  val:[
    window_size: 8
    val_freq: 4000.0
    save_img: False
    rgb2bgr: True
    use_image: False
    max_minibatch: 8
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: False
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  is_train: True
  dist: False
  rank: 0
  world_size: 1

W0609 23:01:26.044368 578568 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 8.6, Driver API Version: 11.6, Runtime API Version: 11.6
W0609 23:01:26.051038 578568 gpu_resources.cc:91] device: 0, cuDNN Version: 8.4.
2023-06-09 23:01:27,140 INFO: Network: NBNet, with parameters: 10,455,235
2023-06-09 23:01:27,140 INFO: NBNet(
  (ConvBlock1): ConvBlock(
    (block): Sequential(
      (0): Conv2D(3, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(3, 32, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool1): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip1): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (2): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (3): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa1): SSA(
    (conv1): Conv2D(64, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(64, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock2): ConvBlock(
    (block): Sequential(
      (0): Conv2D(32, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(32, 64, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool2): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip2): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
    (2): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa2): SSA(
    (conv1): Conv2D(128, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(128, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock3): ConvBlock(
    (block): Sequential(
      (0): Conv2D(64, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(64, 128, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool3): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip3): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(128, 128, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(128, 128, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa3): SSA(
    (conv1): Conv2D(256, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(256, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock4): ConvBlock(
    (block): Sequential(
      (0): Conv2D(128, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(128, 256, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool4): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip4): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(256, 256, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa4): SSA(
    (conv1): Conv2D(512, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(512, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock5): ConvBlock(
    (block): Sequential(
      (0): Conv2D(256, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(256, 512, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv6): Conv2DTranspose(512, 256, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock6): ConvBlock(
    (block): Sequential(
      (0): Conv2D(512, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv7): Conv2DTranspose(256, 128, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock7): ConvBlock(
    (block): Sequential(
      (0): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv8): Conv2DTranspose(128, 64, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock8): ConvBlock(
    (block): Sequential(
      (0): Conv2D(128, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(128, 64, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv9): Conv2DTranspose(64, 32, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock9): ConvBlock(
    (block): Sequential(
      (0): Conv2D(64, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(64, 32, kernel_size=[1, 1], data_format=NCHW)
  )
  (conv10): Conv2D(32, 3, kernel_size=[3, 3], padding=1, data_format=NCHW)
)
2023-06-09 23:01:27,238 INFO: Training statistics:
	Number of train images: 96000
	Dataset enlarge ratio: 1
	Batch size per gpu: 4
	World size (gpu number): 1
	Require iter number per epoch: 24000
	Total epochs: 42; iters: 1000000.
2023-06-09 23:01:27,239 INFO: Number of val images/folders in ValSet: 1280
2023-06-09 23:01:27,239 INFO: Start training from epoch: 0, iter: 0
2023-06-09 23:01:27,735 INFO: 
 Updating Patch_Size to 128 and Batch_Size to 8 

2023-06-09 23:01:42,889 INFO: epoch:0, iter:100, lr: 0.000150 loss: 0.273794  eta: 1 day, 19:02:08, time (data): 0.108
2023-06-09 23:01:53,738 INFO: epoch:0, iter:200, lr: 0.000150 loss: 0.268131  eta: 1 day, 12:36:45, time (data): 0.109
2023-06-09 23:02:04,486 INFO: epoch:0, iter:300, lr: 0.000150 loss: 0.191281  eta: 1 day, 10:21:47, time (data): 0.106
2023-06-09 23:02:15,300 INFO: epoch:0, iter:400, lr: 0.000150 loss: 0.179746  eta: 1 day, 9:16:44, time (data): 0.107
2023-06-09 23:02:26,185 INFO: epoch:0, iter:500, lr: 0.000150 loss: 0.077434  eta: 1 day, 8:39:56, time (data): 0.122
2023-06-09 23:02:37,253 INFO: epoch:0, iter:600, lr: 0.000150 loss: 0.100062  eta: 1 day, 8:20:25, time (data): 0.107
2023-06-09 23:02:48,770 INFO: epoch:0, iter:700, lr: 0.000150 loss: 0.068857  eta: 1 day, 8:17:04, time (data): 0.118
2023-06-09 23:02:59,930 INFO: epoch:0, iter:800, lr: 0.000150 loss: 0.051543  eta: 1 day, 8:07:05, time (data): 0.123
2023-06-09 23:03:11,100 INFO: epoch:0, iter:900, lr: 0.000150 loss: 0.074971  eta: 1 day, 7:59:28, time (data): 0.107
2023-06-09 23:03:22,020 INFO: epoch:0, iter:1000, lr: 0.000150 loss: 0.090328  eta: 1 day, 7:49:11, time (data): 0.111
2023-06-09 23:03:32,776 INFO: epoch:0, iter:1100, lr: 0.000150 loss: 0.065571  eta: 1 day, 7:38:14, time (data): 0.107
2023-06-09 23:03:43,563 INFO: epoch:0, iter:1200, lr: 0.000150 loss: 0.055334  eta: 1 day, 7:29:32, time (data): 0.107
2023-06-09 23:03:54,373 INFO: epoch:0, iter:1300, lr: 0.000150 loss: 0.055663  eta: 1 day, 7:22:25, time (data): 0.119
2023-06-09 23:04:05,490 INFO: epoch:0, iter:1400, lr: 0.000150 loss: 0.055451  eta: 1 day, 7:19:57, time (data): 0.106
2023-06-09 23:04:16,407 INFO: epoch:0, iter:1500, lr: 0.000150 loss: 0.044837  eta: 1 day, 7:15:34, time (data): 0.108
2023-06-09 23:04:27,190 INFO: epoch:0, iter:1600, lr: 0.000150 loss: 0.035315  eta: 1 day, 7:10:19, time (data): 0.112
2023-06-09 23:04:38,041 INFO: epoch:0, iter:1700, lr: 0.000150 loss: 0.058549  eta: 1 day, 7:06:19, time (data): 0.106
2023-06-09 23:04:49,069 INFO: epoch:0, iter:1800, lr: 0.000150 loss: 0.036126  eta: 1 day, 7:04:23, time (data): 0.106
2023-06-09 23:04:59,788 INFO: epoch:0, iter:1900, lr: 0.000150 loss: 0.039941  eta: 1 day, 6:59:56, time (data): 0.107
2023-06-09 23:05:10,992 INFO: epoch:0, iter:2000, lr: 0.000150 loss: 0.044151  eta: 1 day, 6:59:56, time (data): 0.107
2023-06-09 23:05:22,045 INFO: epoch:0, iter:2100, lr: 0.000150 loss: 0.041327  eta: 1 day, 6:58:44, time (data): 0.109
2023-06-09 23:05:33,122 INFO: epoch:0, iter:2200, lr: 0.000150 loss: 0.027318  eta: 1 day, 6:57:48, time (data): 0.108
2023-06-09 23:05:44,366 INFO: epoch:0, iter:2300, lr: 0.000150 loss: 0.034059  eta: 1 day, 6:58:08, time (data): 0.108
2023-06-09 23:05:55,602 INFO: epoch:0, iter:2400, lr: 0.000150 loss: 0.029817  eta: 1 day, 6:58:22, time (data): 0.108
2023-06-09 23:06:06,707 INFO: epoch:0, iter:2500, lr: 0.000150 loss: 0.034953  eta: 1 day, 6:57:43, time (data): 0.107
2023-06-09 23:06:17,532 INFO: epoch:0, iter:2600, lr: 0.000150 loss: 0.039397  eta: 1 day, 6:55:17, time (data): 0.107
2023-06-09 23:06:28,503 INFO: epoch:0, iter:2700, lr: 0.000150 loss: 0.025853  eta: 1 day, 6:53:56, time (data): 0.107
2023-06-09 23:06:39,394 INFO: epoch:0, iter:2800, lr: 0.000150 loss: 0.036118  eta: 1 day, 6:52:11, time (data): 0.108
2023-06-09 23:06:50,286 INFO: epoch:0, iter:2900, lr: 0.000150 loss: 0.033470  eta: 1 day, 6:50:33, time (data): 0.109
2023-06-09 23:07:01,243 INFO: epoch:0, iter:3000, lr: 0.000150 loss: 0.023384  eta: 1 day, 6:49:23, time (data): 0.109
2023-06-09 23:07:12,086 INFO: epoch:0, iter:3100, lr: 0.000150 loss: 0.015583  eta: 1 day, 6:47:40, time (data): 0.108
2023-06-09 23:07:23,072 INFO: epoch:0, iter:3200, lr: 0.000150 loss: 0.169059  eta: 1 day, 6:46:47, time (data): 0.106
2023-06-09 23:07:33,848 INFO: epoch:0, iter:3300, lr: 0.000150 loss: 0.031250  eta: 1 day, 6:44:53, time (data): 0.108
2023-06-09 23:07:45,179 INFO: epoch:0, iter:3400, lr: 0.000150 loss: 0.021480  eta: 1 day, 6:45:48, time (data): 0.122
2023-06-09 23:07:56,242 INFO: epoch:0, iter:3500, lr: 0.000150 loss: 0.023209  eta: 1 day, 6:45:22, time (data): 0.108
2023-06-09 23:08:07,235 INFO: epoch:0, iter:3600, lr: 0.000150 loss: 0.013685  eta: 1 day, 6:44:38, time (data): 0.119
2023-06-09 23:08:18,101 INFO: epoch:0, iter:3700, lr: 0.000150 loss: 0.024761  eta: 1 day, 6:43:22, time (data): 0.108
2023-06-09 23:08:28,917 INFO: epoch:0, iter:3800, lr: 0.000150 loss: 0.016356  eta: 1 day, 6:41:56, time (data): 0.109
2023-06-09 23:08:39,995 INFO: epoch:0, iter:3900, lr: 0.000150 loss: 0.026267  eta: 1 day, 6:41:41, time (data): 0.108
2023-06-09 23:08:51,018 INFO: epoch:0, iter:4000, lr: 0.000150 loss: 0.017459  eta: 1 day, 6:41:13, time (data): 0.112
2023-06-09 23:09:01,992 INFO: epoch:0, iter:4100, lr: 0.000150 loss: 0.016453  eta: 1 day, 6:40:33, time (data): 0.109
2023-06-09 23:09:12,884 INFO: epoch:0, iter:4200, lr: 0.000150 loss: 0.017169  eta: 1 day, 6:39:35, time (data): 0.108
2023-06-09 23:09:23,931 INFO: epoch:0, iter:4300, lr: 0.000150 loss: 0.018256  eta: 1 day, 6:39:16, time (data): 0.120
2023-06-09 23:09:34,732 INFO: epoch:0, iter:4400, lr: 0.000150 loss: 0.024084  eta: 1 day, 6:38:01, time (data): 0.108
2023-06-09 23:09:45,827 INFO: epoch:0, iter:4500, lr: 0.000150 loss: 0.012444  eta: 1 day, 6:37:54, time (data): 0.109
2023-06-09 23:09:56,862 INFO: epoch:0, iter:4600, lr: 0.000150 loss: 0.021824  eta: 1 day, 6:37:33, time (data): 0.108
2023-06-09 23:10:07,733 INFO: epoch:0, iter:4700, lr: 0.000150 loss: 0.019231  eta: 1 day, 6:36:39, time (data): 0.107
2023-06-09 23:10:18,738 INFO: epoch:0, iter:4800, lr: 0.000150 loss: 0.018957  eta: 1 day, 6:36:14, time (data): 0.108
2023-06-09 23:10:29,834 INFO: epoch:0, iter:4900, lr: 0.000150 loss: 0.015893  eta: 1 day, 6:36:08, time (data): 0.119
2023-06-09 23:10:40,684 INFO: epoch:0, iter:5000, lr: 0.000150 loss: 0.018874  eta: 1 day, 6:35:13, time (data): 0.109
2023-06-09 23:10:51,647 INFO: epoch:0, iter:5100, lr: 0.000150 loss: 0.017498  eta: 1 day, 6:34:41, time (data): 0.108
2023-06-09 23:11:03,240 INFO: epoch:0, iter:5200, lr: 0.000150 loss: 0.022568  eta: 1 day, 6:36:11, time (data): 0.108
2023-06-09 23:11:14,110 INFO: epoch:0, iter:5300, lr: 0.000150 loss: 0.016759  eta: 1 day, 6:35:22, time (data): 0.124
2023-06-09 23:11:25,420 INFO: epoch:0, iter:5400, lr: 0.000150 loss: 0.018156  eta: 1 day, 6:35:55, time (data): 0.107
2023-06-09 23:11:36,246 INFO: epoch:0, iter:5500, lr: 0.000150 loss: 0.018274  eta: 1 day, 6:34:59, time (data): 0.108
2023-06-09 23:11:47,068 INFO: epoch:0, iter:5600, lr: 0.000150 loss: 0.018383  eta: 1 day, 6:34:04, time (data): 0.108
2023-06-09 23:11:57,879 INFO: epoch:0, iter:5700, lr: 0.000150 loss: 0.013720  eta: 1 day, 6:33:08, time (data): 0.109
2023-06-09 23:12:08,970 INFO: epoch:0, iter:5800, lr: 0.000150 loss: 0.015519  eta: 1 day, 6:33:02, time (data): 0.106
2023-06-09 23:12:19,768 INFO: epoch:0, iter:5900, lr: 0.000150 loss: 0.012769  eta: 1 day, 6:32:06, time (data): 0.121
2023-06-09 23:12:30,729 INFO: epoch:0, iter:6000, lr: 0.000150 loss: 0.019379  eta: 1 day, 6:31:39, time (data): 0.107
2023-06-09 23:12:41,626 INFO: epoch:0, iter:6100, lr: 0.000150 loss: 0.010153  eta: 1 day, 6:31:02, time (data): 0.109
2023-06-09 23:12:52,830 INFO: epoch:0, iter:6200, lr: 0.000150 loss: 0.020261  eta: 1 day, 6:31:15, time (data): 0.119
2023-06-09 23:13:03,825 INFO: epoch:0, iter:6300, lr: 0.000150 loss: 0.010714  eta: 1 day, 6:30:54, time (data): 0.107
2023-06-09 23:13:14,649 INFO: epoch:0, iter:6400, lr: 0.000150 loss: 0.012424  eta: 1 day, 6:30:08, time (data): 0.108
2023-06-09 23:13:25,832 INFO: epoch:0, iter:6500, lr: 0.000150 loss: 0.011600  eta: 1 day, 6:30:17, time (data): 0.109
2023-06-09 23:13:37,401 INFO: epoch:0, iter:6600, lr: 0.000150 loss: 0.012154  eta: 1 day, 6:31:23, time (data): 0.120
2023-06-09 23:13:48,928 INFO: epoch:0, iter:6700, lr: 0.000150 loss: 0.011276  eta: 1 day, 6:32:21, time (data): 0.119
2023-06-09 23:14:00,313 INFO: epoch:0, iter:6800, lr: 0.000150 loss: 0.017256  eta: 1 day, 6:32:56, time (data): 0.108
2023-06-09 23:14:11,601 INFO: epoch:0, iter:6900, lr: 0.000150 loss: 0.012049  eta: 1 day, 6:33:16, time (data): 0.107
2023-06-09 23:14:22,459 INFO: epoch:0, iter:7000, lr: 0.000150 loss: 0.014952  eta: 1 day, 6:32:34, time (data): 0.110
2023-06-09 23:14:33,798 INFO: epoch:0, iter:7100, lr: 0.000150 loss: 0.014701  eta: 1 day, 6:33:00, time (data): 0.106
2023-06-09 23:14:44,700 INFO: epoch:0, iter:7200, lr: 0.000150 loss: 0.011929  eta: 1 day, 6:32:25, time (data): 0.107
2023-06-09 23:14:55,620 INFO: epoch:0, iter:7300, lr: 0.000150 loss: 0.015503  eta: 1 day, 6:31:53, time (data): 0.107
2023-06-09 23:15:06,991 INFO: epoch:0, iter:7400, lr: 0.000150 loss: 0.016213  eta: 1 day, 6:32:22, time (data): 0.108
2023-06-09 23:15:18,151 INFO: epoch:0, iter:7500, lr: 0.000150 loss: 0.012131  eta: 1 day, 6:32:22, time (data): 0.107
2023-06-09 23:15:28,951 INFO: epoch:0, iter:7600, lr: 0.000150 loss: 0.010946  eta: 1 day, 6:31:35, time (data): 0.108
2023-06-09 23:15:39,877 INFO: epoch:0, iter:7700, lr: 0.000150 loss: 0.013226  eta: 1 day, 6:31:05, time (data): 0.108
2023-06-09 23:15:50,899 INFO: epoch:0, iter:7800, lr: 0.000150 loss: 0.011054  eta: 1 day, 6:30:47, time (data): 0.110
2023-06-09 23:16:01,763 INFO: epoch:0, iter:7900, lr: 0.000150 loss: 0.014108  eta: 1 day, 6:30:10, time (data): 0.108
2023-06-09 23:16:13,215 INFO: epoch:0, iter:8000, lr: 0.000150 loss: 0.013619  eta: 1 day, 6:30:47, time (data): 0.109
2023-06-09 23:16:24,185 INFO: epoch:0, iter:8100, lr: 0.000150 loss: 0.012595  eta: 1 day, 6:30:23, time (data): 0.109
2023-06-09 23:16:35,468 INFO: epoch:0, iter:8200, lr: 0.000150 loss: 0.011184  eta: 1 day, 6:30:37, time (data): 0.122
2023-06-09 23:16:47,631 INFO: epoch:0, iter:8300, lr: 0.000150 loss: 0.010062  eta: 1 day, 6:32:36, time (data): 0.121
2023-06-09 23:16:59,197 INFO: epoch:0, iter:8400, lr: 0.000150 loss: 0.010683  eta: 1 day, 6:33:22, time (data): 0.127
2023-06-09 23:17:10,561 INFO: epoch:0, iter:8500, lr: 0.000150 loss: 0.011397  eta: 1 day, 6:33:42, time (data): 0.110
2023-06-09 23:17:21,682 INFO: epoch:0, iter:8600, lr: 0.000150 loss: 0.014826  eta: 1 day, 6:33:34, time (data): 0.109
2023-06-09 23:17:32,841 INFO: epoch:0, iter:8700, lr: 0.000150 loss: 0.011465  eta: 1 day, 6:33:30, time (data): 0.108
2023-06-09 23:17:43,847 INFO: epoch:0, iter:8800, lr: 0.000150 loss: 0.015841  eta: 1 day, 6:33:08, time (data): 0.108
2023-06-09 23:17:54,870 INFO: epoch:0, iter:8900, lr: 0.000150 loss: 0.015969  eta: 1 day, 6:32:49, time (data): 0.109
2023-06-09 23:18:06,672 INFO: epoch:0, iter:9000, lr: 0.000150 loss: 0.017743  eta: 1 day, 6:33:56, time (data): 0.108
2023-06-09 23:18:17,586 INFO: epoch:0, iter:9100, lr: 0.000150 loss: 0.014042  eta: 1 day, 6:33:24, time (data): 0.109
2023-06-09 23:18:28,574 INFO: epoch:0, iter:9200, lr: 0.000150 loss: 0.013844  eta: 1 day, 6:33:01, time (data): 0.107
2023-06-09 23:18:40,205 INFO: epoch:0, iter:9300, lr: 0.000150 loss: 0.010712  eta: 1 day, 6:33:46, time (data): 0.108
2023-06-09 23:18:51,041 INFO: epoch:0, iter:9400, lr: 0.000150 loss: 0.014336  eta: 1 day, 6:33:07, time (data): 0.108
2023-06-09 23:19:01,819 INFO: epoch:0, iter:9500, lr: 0.000150 loss: 0.014745  eta: 1 day, 6:32:22, time (data): 0.109
2023-06-09 23:19:12,683 INFO: epoch:0, iter:9600, lr: 0.000150 loss: 0.010239  eta: 1 day, 6:31:46, time (data): 0.109
2023-06-09 23:19:23,466 INFO: epoch:0, iter:9700, lr: 0.000150 loss: 0.011319  eta: 1 day, 6:31:03, time (data): 0.109
2023-06-09 23:19:35,147 INFO: epoch:0, iter:9800, lr: 0.000150 loss: 0.009823  eta: 1 day, 6:31:51, time (data): 0.106
2023-06-09 23:19:46,287 INFO: epoch:0, iter:9900, lr: 0.000150 loss: 0.011805  eta: 1 day, 6:31:44, time (data): 0.109
2023-06-09 23:19:57,190 INFO: epoch:0, iter:10000, lr: 0.000150 loss: 0.010686  eta: 1 day, 6:31:14, time (data): 0.109
2023-06-09 23:20:08,329 INFO: epoch:0, iter:10100, lr: 0.000150 loss: 0.013607  eta: 1 day, 6:31:06, time (data): 0.108
2023-06-09 23:20:19,620 INFO: epoch:0, iter:10200, lr: 0.000150 loss: 0.007510  eta: 1 day, 6:31:14, time (data): 0.109
2023-06-09 23:20:30,593 INFO: epoch:0, iter:10300, lr: 0.000150 loss: 0.009874  eta: 1 day, 6:30:51, time (data): 0.123
2023-06-09 23:20:41,834 INFO: epoch:0, iter:10400, lr: 0.000150 loss: 0.008509  eta: 1 day, 6:30:53, time (data): 0.120
2023-06-09 23:20:53,202 INFO: epoch:0, iter:10500, lr: 0.000150 loss: 0.015485  eta: 1 day, 6:31:07, time (data): 0.120
2023-06-09 23:21:04,210 INFO: epoch:0, iter:10600, lr: 0.000150 loss: 0.012714  eta: 1 day, 6:30:47, time (data): 0.106
2023-06-09 23:21:15,585 INFO: epoch:0, iter:10700, lr: 0.000150 loss: 0.021327  eta: 1 day, 6:31:01, time (data): 0.108
2023-06-09 23:21:26,477 INFO: epoch:0, iter:10800, lr: 0.000150 loss: 0.011788  eta: 1 day, 6:30:31, time (data): 0.110
2023-06-09 23:21:37,296 INFO: epoch:0, iter:10900, lr: 0.000150 loss: 0.008999  eta: 1 day, 6:29:54, time (data): 0.109
2023-06-09 23:21:48,722 INFO: epoch:0, iter:11000, lr: 0.000150 loss: 0.009994  eta: 1 day, 6:30:12, time (data): 0.109
2023-06-09 23:21:59,777 INFO: epoch:0, iter:11100, lr: 0.000150 loss: 0.007915  eta: 1 day, 6:29:56, time (data): 0.121
2023-06-09 23:22:11,217 INFO: epoch:0, iter:11200, lr: 0.000150 loss: 0.012150  eta: 1 day, 6:30:15, time (data): 0.108
2023-06-09 23:22:22,253 INFO: epoch:0, iter:11300, lr: 0.000150 loss: 0.009759  eta: 1 day, 6:29:58, time (data): 0.117
2023-06-09 23:22:33,070 INFO: epoch:0, iter:11400, lr: 0.000150 loss: 0.010195  eta: 1 day, 6:29:22, time (data): 0.109
2023-06-09 23:22:44,510 INFO: epoch:0, iter:11500, lr: 0.000150 loss: 0.011188  eta: 1 day, 6:29:40, time (data): 0.109
2023-06-09 23:22:55,736 INFO: epoch:0, iter:11600, lr: 0.000150 loss: 0.012324  eta: 1 day, 6:29:39, time (data): 0.120
2023-06-09 23:23:07,007 INFO: epoch:0, iter:11700, lr: 0.000150 loss: 0.010487  eta: 1 day, 6:29:42, time (data): 0.110
2023-06-09 23:23:17,924 INFO: epoch:0, iter:11800, lr: 0.000150 loss: 0.009531  eta: 1 day, 6:29:14, time (data): 0.110
2023-06-09 23:23:29,308 INFO: epoch:0, iter:11900, lr: 0.000150 loss: 0.011646  eta: 1 day, 6:29:26, time (data): 0.111
2023-06-09 23:23:40,097 INFO: epoch:0, iter:12000, lr: 0.000150 loss: 0.006011  eta: 1 day, 6:28:49, time (data): 0.107
2023-06-09 23:23:51,198 INFO: epoch:0, iter:12100, lr: 0.000150 loss: 0.012856  eta: 1 day, 6:28:37, time (data): 0.107
2023-06-09 23:24:02,112 INFO: epoch:0, iter:12200, lr: 0.000150 loss: 0.012081  eta: 1 day, 6:28:11, time (data): 0.112
2023-06-09 23:24:13,047 INFO: epoch:0, iter:12300, lr: 0.000150 loss: 0.014487  eta: 1 day, 6:27:46, time (data): 0.120
2023-06-09 23:24:24,251 INFO: epoch:0, iter:12400, lr: 0.000150 loss: 0.008101  eta: 1 day, 6:27:43, time (data): 0.107
2023-06-09 23:24:35,213 INFO: epoch:0, iter:12500, lr: 0.000150 loss: 0.013592  eta: 1 day, 6:27:21, time (data): 0.130
2023-06-09 23:24:46,468 INFO: epoch:0, iter:12600, lr: 0.000150 loss: 0.010978  eta: 1 day, 6:27:21, time (data): 0.109
2023-06-09 23:24:57,367 INFO: epoch:0, iter:12700, lr: 0.000150 loss: 0.006334  eta: 1 day, 6:26:54, time (data): 0.112
2023-06-09 23:25:08,262 INFO: epoch:0, iter:12800, lr: 0.000150 loss: 0.007435  eta: 1 day, 6:26:27, time (data): 0.109
2023-06-09 23:25:19,452 INFO: epoch:0, iter:12900, lr: 0.000150 loss: 0.012642  eta: 1 day, 6:26:23, time (data): 0.106
2023-06-09 23:25:30,449 INFO: epoch:0, iter:13000, lr: 0.000150 loss: 0.011778  eta: 1 day, 6:26:04, time (data): 0.110
2023-06-09 23:25:41,307 INFO: epoch:0, iter:13100, lr: 0.000150 loss: 0.011064  eta: 1 day, 6:25:34, time (data): 0.107
2023-06-09 23:25:52,160 INFO: epoch:0, iter:13200, lr: 0.000150 loss: 0.009246  eta: 1 day, 6:25:05, time (data): 0.110
2023-06-09 23:26:03,032 INFO: epoch:0, iter:13300, lr: 0.000150 loss: 0.009604  eta: 1 day, 6:24:37, time (data): 0.110
2023-06-09 23:26:14,212 INFO: epoch:0, iter:13400, lr: 0.000150 loss: 0.009009  eta: 1 day, 6:24:32, time (data): 0.107
2023-06-09 23:26:25,337 INFO: epoch:0, iter:13500, lr: 0.000150 loss: 0.008676  eta: 1 day, 6:24:23, time (data): 0.108
2023-06-09 23:26:36,128 INFO: epoch:0, iter:13600, lr: 0.000150 loss: 0.010493  eta: 1 day, 6:23:50, time (data): 0.111
2023-06-09 23:26:46,920 INFO: epoch:0, iter:13700, lr: 0.000150 loss: 0.007124  eta: 1 day, 6:23:17, time (data): 0.107
2023-06-09 23:26:58,424 INFO: epoch:0, iter:13800, lr: 0.000150 loss: 0.012358  eta: 1 day, 6:23:36, time (data): 0.109
2023-06-09 23:27:09,238 INFO: epoch:0, iter:13900, lr: 0.000150 loss: 0.009083  eta: 1 day, 6:23:05, time (data): 0.110
2023-06-09 23:27:20,368 INFO: epoch:0, iter:14000, lr: 0.000150 loss: 0.009358  eta: 1 day, 6:22:56, time (data): 0.109
2023-06-09 23:27:31,667 INFO: epoch:0, iter:14100, lr: 0.000150 loss: 0.007613  eta: 1 day, 6:23:00, time (data): 0.120
2023-06-09 23:27:42,489 INFO: epoch:0, iter:14200, lr: 0.000150 loss: 0.011175  eta: 1 day, 6:22:30, time (data): 0.108
2023-06-09 23:27:53,658 INFO: epoch:0, iter:14300, lr: 0.000150 loss: 0.017107  eta: 1 day, 6:22:24, time (data): 0.106
2023-06-09 23:28:04,521 INFO: epoch:0, iter:14400, lr: 0.000150 loss: 0.017264  eta: 1 day, 6:21:57, time (data): 0.175
2023-06-09 23:28:16,116 INFO: epoch:0, iter:14500, lr: 0.000150 loss: 0.008459  eta: 1 day, 6:22:20, time (data): 0.109
2023-06-09 23:28:27,388 INFO: epoch:0, iter:14600, lr: 0.000150 loss: 0.007832  eta: 1 day, 6:22:21, time (data): 0.121
2023-06-09 23:28:38,764 INFO: epoch:0, iter:14700, lr: 0.000150 loss: 0.009384  eta: 1 day, 6:22:28, time (data): 0.107
2023-06-09 23:28:49,737 INFO: epoch:0, iter:14800, lr: 0.000150 loss: 0.011823  eta: 1 day, 6:22:09, time (data): 0.109
2023-06-09 23:29:00,474 INFO: epoch:0, iter:14900, lr: 0.000150 loss: 0.006954  eta: 1 day, 6:21:34, time (data): 0.113
2023-06-09 23:29:11,516 INFO: epoch:0, iter:15000, lr: 0.000150 loss: 0.013295  eta: 1 day, 6:21:20, time (data): 0.106
2023-06-09 23:29:22,324 INFO: epoch:0, iter:15100, lr: 0.000150 loss: 0.012531  eta: 1 day, 6:20:50, time (data): 0.108
2023-06-09 23:29:33,193 INFO: epoch:0, iter:15200, lr: 0.000150 loss: 0.009433  eta: 1 day, 6:20:24, time (data): 0.127
2023-06-09 23:29:44,153 INFO: epoch:0, iter:15300, lr: 0.000150 loss: 0.007431  eta: 1 day, 6:20:05, time (data): 0.106
2023-06-09 23:29:54,957 INFO: epoch:0, iter:15400, lr: 0.000150 loss: 0.012193  eta: 1 day, 6:19:35, time (data): 0.107
2023-06-09 23:30:05,825 INFO: epoch:0, iter:15500, lr: 0.000150 loss: 0.009143  eta: 1 day, 6:19:10, time (data): 0.118
2023-06-09 23:30:16,536 INFO: epoch:0, iter:15600, lr: 0.000150 loss: 0.009609  eta: 1 day, 6:18:35, time (data): 0.106
2023-06-09 23:30:27,258 INFO: epoch:0, iter:15700, lr: 0.000150 loss: 0.011437  eta: 1 day, 6:18:02, time (data): 0.107
2023-06-09 23:30:38,369 INFO: epoch:0, iter:15800, lr: 0.000150 loss: 0.010817  eta: 1 day, 6:17:52, time (data): 0.107
2023-06-09 23:30:49,514 INFO: epoch:0, iter:15900, lr: 0.000150 loss: 0.011924  eta: 1 day, 6:17:45, time (data): 0.108
2023-06-09 23:31:00,258 INFO: epoch:0, iter:16000, lr: 0.000150 loss: 0.006051  eta: 1 day, 6:17:13, time (data): 0.112
2023-06-09 23:31:11,013 INFO: epoch:0, iter:16100, lr: 0.000150 loss: 0.009481  eta: 1 day, 6:16:42, time (data): 0.105
2023-06-09 23:31:22,076 INFO: epoch:0, iter:16200, lr: 0.000150 loss: 0.008996  eta: 1 day, 6:16:30, time (data): 0.105
2023-06-09 23:31:32,850 INFO: epoch:0, iter:16300, lr: 0.000150 loss: 0.009097  eta: 1 day, 6:16:01, time (data): 0.109
2023-06-09 23:31:43,798 INFO: epoch:0, iter:16400, lr: 0.000150 loss: 0.011328  eta: 1 day, 6:15:42, time (data): 0.106
2023-06-09 23:31:54,539 INFO: epoch:0, iter:16500, lr: 0.000150 loss: 0.009692  eta: 1 day, 6:15:11, time (data): 0.104
2023-06-09 23:32:05,051 INFO: epoch:0, iter:16600, lr: 0.000150 loss: 0.010732  eta: 1 day, 6:14:27, time (data): 0.105
2023-06-09 23:32:16,169 INFO: epoch:0, iter:16700, lr: 0.000150 loss: 0.012581  eta: 1 day, 6:14:18, time (data): 0.105
2023-06-09 23:32:26,942 INFO: epoch:0, iter:16800, lr: 0.000150 loss: 0.012350  eta: 1 day, 6:13:50, time (data): 0.107
2023-06-09 23:32:37,637 INFO: epoch:0, iter:16900, lr: 0.000150 loss: 0.006383  eta: 1 day, 6:13:17, time (data): 0.108
2023-06-09 23:32:48,526 INFO: epoch:0, iter:17000, lr: 0.000150 loss: 0.007251  eta: 1 day, 6:12:56, time (data): 0.106
2023-06-09 23:32:59,848 INFO: epoch:0, iter:17100, lr: 0.000150 loss: 0.009225  eta: 1 day, 6:12:59, time (data): 0.119
2023-06-09 23:33:10,843 INFO: epoch:0, iter:17200, lr: 0.000150 loss: 0.010592  eta: 1 day, 6:12:44, time (data): 0.106
2023-06-09 23:33:21,503 INFO: epoch:0, iter:17300, lr: 0.000150 loss: 0.007174  eta: 1 day, 6:12:10, time (data): 0.107
2023-06-09 23:33:32,424 INFO: epoch:0, iter:17400, lr: 0.000150 loss: 0.005983  eta: 1 day, 6:11:51, time (data): 0.108
2023-06-09 23:33:43,414 INFO: epoch:0, iter:17500, lr: 0.000150 loss: 0.012772  eta: 1 day, 6:11:36, time (data): 0.106
2023-06-09 23:33:54,139 INFO: epoch:0, iter:17600, lr: 0.000150 loss: 0.012606  eta: 1 day, 6:11:06, time (data): 0.118
2023-06-09 23:34:05,005 INFO: epoch:0, iter:17700, lr: 0.000150 loss: 0.007057  eta: 1 day, 6:10:44, time (data): 0.109
2023-06-09 23:34:15,871 INFO: epoch:0, iter:17800, lr: 0.000150 loss: 0.010684  eta: 1 day, 6:10:22, time (data): 0.109
2023-06-09 23:34:27,110 INFO: epoch:0, iter:17900, lr: 0.000150 loss: 0.008083  eta: 1 day, 6:10:21, time (data): 0.105
2023-06-09 23:34:37,777 INFO: epoch:0, iter:18000, lr: 0.000150 loss: 0.006487  eta: 1 day, 6:09:48, time (data): 0.107
2023-06-09 23:34:48,403 INFO: epoch:0, iter:18100, lr: 0.000150 loss: 0.015945  eta: 1 day, 6:09:14, time (data): 0.106
2023-06-09 23:34:59,197 INFO: epoch:0, iter:18200, lr: 0.000150 loss: 0.013010  eta: 1 day, 6:08:49, time (data): 0.105
2023-06-09 23:35:09,955 INFO: epoch:0, iter:18300, lr: 0.000150 loss: 0.010222  eta: 1 day, 6:08:22, time (data): 0.107
2023-06-09 23:35:20,607 INFO: epoch:0, iter:18400, lr: 0.000150 loss: 0.011027  eta: 1 day, 6:07:49, time (data): 0.105
2023-06-09 23:35:31,334 INFO: epoch:0, iter:18500, lr: 0.000150 loss: 0.011018  eta: 1 day, 6:07:21, time (data): 0.106
2023-06-09 23:35:42,070 INFO: epoch:0, iter:18600, lr: 0.000150 loss: 0.010959  eta: 1 day, 6:06:53, time (data): 0.106
2023-06-09 23:35:52,779 INFO: epoch:0, iter:18700, lr: 0.000150 loss: 0.010190  eta: 1 day, 6:06:25, time (data): 0.106
2023-06-09 23:36:03,580 INFO: epoch:0, iter:18800, lr: 0.000150 loss: 0.007914  eta: 1 day, 6:06:01, time (data): 0.118
2023-06-09 23:36:14,374 INFO: epoch:0, iter:18900, lr: 0.000150 loss: 0.009434  eta: 1 day, 6:05:37, time (data): 0.106
2023-06-09 23:36:25,089 INFO: epoch:0, iter:19000, lr: 0.000150 loss: 0.012178  eta: 1 day, 6:05:09, time (data): 0.107
2023-06-09 23:36:35,854 INFO: epoch:0, iter:19100, lr: 0.000150 loss: 0.010706  eta: 1 day, 6:04:44, time (data): 0.108
2023-06-09 23:36:46,754 INFO: epoch:0, iter:19200, lr: 0.000150 loss: 0.009424  eta: 1 day, 6:04:26, time (data): 0.109
2023-06-09 23:36:57,952 INFO: epoch:0, iter:19300, lr: 0.000150 loss: 0.009238  eta: 1 day, 6:04:23, time (data): 0.107
2023-06-09 23:37:08,782 INFO: epoch:0, iter:19400, lr: 0.000150 loss: 0.008055  eta: 1 day, 6:04:01, time (data): 0.108
2023-06-09 23:37:19,510 INFO: epoch:0, iter:19500, lr: 0.000150 loss: 0.011222  eta: 1 day, 6:03:34, time (data): 0.107
2023-06-09 23:37:30,339 INFO: epoch:0, iter:19600, lr: 0.000150 loss: 0.007848  eta: 1 day, 6:03:13, time (data): 0.107
2023-06-09 23:37:41,274 INFO: epoch:0, iter:19700, lr: 0.000150 loss: 0.006660  eta: 1 day, 6:02:57, time (data): 0.108
2023-06-09 23:37:52,009 INFO: epoch:0, iter:19800, lr: 0.000150 loss: 0.011457  eta: 1 day, 6:02:31, time (data): 0.109
2023-06-09 23:38:03,016 INFO: epoch:0, iter:19900, lr: 0.000150 loss: 0.007757  eta: 1 day, 6:02:19, time (data): 0.108
2023-06-09 23:38:14,077 INFO: epoch:0, iter:20000, lr: 0.000150 loss: 0.007037  eta: 1 day, 6:02:09, time (data): 0.108
2023-06-09 23:38:25,026 INFO: epoch:0, iter:20100, lr: 0.000150 loss: 0.006197  eta: 1 day, 6:01:54, time (data): 0.123
2023-06-09 23:38:36,447 INFO: epoch:0, iter:20200, lr: 0.000150 loss: 0.012718  eta: 1 day, 6:02:02, time (data): 0.108
2023-06-09 23:38:47,258 INFO: epoch:0, iter:20300, lr: 0.000150 loss: 0.013124  eta: 1 day, 6:01:40, time (data): 0.106
2023-06-09 23:38:58,099 INFO: epoch:0, iter:20400, lr: 0.000150 loss: 0.011064  eta: 1 day, 6:01:19, time (data): 0.109
2023-06-09 23:39:09,455 INFO: epoch:0, iter:20500, lr: 0.000150 loss: 0.006646  eta: 1 day, 6:01:24, time (data): 0.109
2023-06-09 23:39:20,575 INFO: epoch:0, iter:20600, lr: 0.000150 loss: 0.017261  eta: 1 day, 6:01:17, time (data): 0.108
2023-06-09 23:39:31,642 INFO: epoch:0, iter:20700, lr: 0.000150 loss: 0.013237  eta: 1 day, 6:01:07, time (data): 0.111
2023-06-09 23:39:43,065 INFO: epoch:0, iter:20800, lr: 0.000150 loss: 0.036355  eta: 1 day, 6:01:15, time (data): 0.107
2023-06-09 23:39:54,328 INFO: epoch:0, iter:20900, lr: 0.000150 loss: 0.009984  eta: 1 day, 6:01:14, time (data): 0.108
2023-06-09 23:40:05,171 INFO: epoch:0, iter:21000, lr: 0.000150 loss: 0.007434  eta: 1 day, 6:00:54, time (data): 0.110
2023-06-09 23:40:16,047 INFO: epoch:0, iter:21100, lr: 0.000150 loss: 0.010159  eta: 1 day, 6:00:35, time (data): 0.108
2023-06-09 23:40:26,930 INFO: epoch:0, iter:21200, lr: 0.000150 loss: 0.007506  eta: 1 day, 6:00:17, time (data): 0.108
2023-06-09 23:40:37,771 INFO: epoch:0, iter:21300, lr: 0.000150 loss: 0.007740  eta: 1 day, 5:59:57, time (data): 0.109
2023-06-09 23:40:48,650 INFO: epoch:0, iter:21400, lr: 0.000150 loss: 0.007434  eta: 1 day, 5:59:39, time (data): 0.107
2023-06-09 23:41:00,062 INFO: epoch:0, iter:21500, lr: 0.000150 loss: 0.009073  eta: 1 day, 5:59:45, time (data): 0.120
2023-06-09 23:41:10,982 INFO: epoch:0, iter:21600, lr: 0.000150 loss: 0.009156  eta: 1 day, 5:59:29, time (data): 0.107
2023-06-09 23:41:21,898 INFO: epoch:0, iter:21700, lr: 0.000150 loss: 0.009487  eta: 1 day, 5:59:13, time (data): 0.109
2023-06-09 23:41:32,843 INFO: epoch:0, iter:21800, lr: 0.000150 loss: 0.009627  eta: 1 day, 5:58:58, time (data): 0.108
2023-06-09 23:41:43,932 INFO: epoch:0, iter:21900, lr: 0.000150 loss: 0.009593  eta: 1 day, 5:58:49, time (data): 0.126
2023-06-09 23:41:55,337 INFO: epoch:0, iter:22000, lr: 0.000150 loss: 0.008397  eta: 1 day, 5:58:54, time (data): 0.108
2023-06-09 23:42:06,244 INFO: epoch:0, iter:22100, lr: 0.000150 loss: 0.006604  eta: 1 day, 5:58:38, time (data): 0.120
2023-06-09 23:42:17,119 INFO: epoch:0, iter:22200, lr: 0.000150 loss: 0.013360  eta: 1 day, 5:58:20, time (data): 0.107
2023-06-09 23:42:27,946 INFO: epoch:0, iter:22300, lr: 0.000150 loss: 0.007857  eta: 1 day, 5:57:59, time (data): 0.106
2023-06-09 23:42:38,785 INFO: epoch:0, iter:22400, lr: 0.000150 loss: 0.006967  eta: 1 day, 5:57:40, time (data): 0.107
2023-06-09 23:42:50,743 INFO: epoch:0, iter:22500, lr: 0.000150 loss: 0.008266  eta: 1 day, 5:58:09, time (data): 0.121
2023-06-09 23:43:01,584 INFO: epoch:0, iter:22600, lr: 0.000150 loss: 0.009254  eta: 1 day, 5:57:50, time (data): 0.107
2023-06-09 23:43:12,386 INFO: epoch:0, iter:22700, lr: 0.000150 loss: 0.011179  eta: 1 day, 5:57:28, time (data): 0.110
2023-06-09 23:43:23,128 INFO: epoch:0, iter:22800, lr: 0.000150 loss: 0.006456  eta: 1 day, 5:57:05, time (data): 0.106
2023-06-09 23:43:34,529 INFO: epoch:0, iter:22900, lr: 0.000150 loss: 0.008146  eta: 1 day, 5:57:09, time (data): 0.107
2023-06-09 23:43:45,688 INFO: epoch:0, iter:23000, lr: 0.000150 loss: 0.008570  eta: 1 day, 5:57:04, time (data): 0.107
2023-06-09 23:43:56,729 INFO: epoch:0, iter:23100, lr: 0.000150 loss: 0.009212  eta: 1 day, 5:56:53, time (data): 0.109
2023-06-09 23:44:07,804 INFO: epoch:0, iter:23200, lr: 0.000150 loss: 0.006354  eta: 1 day, 5:56:43, time (data): 0.109
2023-06-09 23:44:18,647 INFO: epoch:0, iter:23300, lr: 0.000150 loss: 0.008334  eta: 1 day, 5:56:24, time (data): 0.107
2023-06-09 23:44:29,620 INFO: epoch:0, iter:23400, lr: 0.000150 loss: 0.012084  eta: 1 day, 5:56:11, time (data): 0.123
2023-06-09 23:44:41,060 INFO: epoch:0, iter:23500, lr: 0.000150 loss: 0.008860  eta: 1 day, 5:56:16, time (data): 0.107
2023-06-09 23:44:51,934 INFO: epoch:0, iter:23600, lr: 0.000150 loss: 0.008827  eta: 1 day, 5:55:59, time (data): 0.107
2023-06-09 23:45:02,979 INFO: epoch:0, iter:23700, lr: 0.000150 loss: 0.007146  eta: 1 day, 5:55:48, time (data): 0.107
2023-06-09 23:45:14,214 INFO: epoch:0, iter:23800, lr: 0.000150 loss: 0.007548  eta: 1 day, 5:55:45, time (data): 0.107
2023-06-09 23:45:25,653 INFO: epoch:0, iter:23900, lr: 0.000150 loss: 0.007287  eta: 1 day, 5:55:50, time (data): 0.109
2023-06-09 23:45:36,794 INFO: epoch:0, iter:24000, lr: 0.000150 loss: 0.006491  eta: 1 day, 5:55:43, time (data): 0.106
2023-06-09 23:45:36,838 INFO: Saving models and training states on epoch 0.
Traceback (most recent call last):
  File "train.py", line 257, in <module>
    main()
  File "train.py", line 231, in main
    current_metric = model.validation(val_loader, current_iter,
  File "/root/autodl-tmp/Restormer_Paddle-main/models/base_model.py", line 46, in validation
    return self.nondist_validation(dataloader, current_iter,
  File "/root/autodl-tmp/Restormer_Paddle-main/models/image_restoration_model.py", line 222, in nondist_validation
    test()
  File "/root/autodl-tmp/Restormer_Paddle-main/models/image_restoration_model.py", line 175, in pad_test
    self.nonpad_test(img)
  File "/root/autodl-tmp/Restormer_Paddle-main/models/image_restoration_model.py", line 192, in nonpad_test
    pred = self.net_g(img)
  File "/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 930, in __call__
    return self._dygraph_call_func(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 915, in _dygraph_call_func
    outputs = self.forward(*inputs, **kwargs)
  File "/root/autodl-tmp/Restormer_Paddle-main/models/archs/NBNet.py", line 142, in forward
    skip1 = self.ssa1(skip1, up9)
  File "/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 930, in __call__
    return self._dygraph_call_func(*inputs, **kwargs)
  File "/root/miniconda3/lib/python3.8/site-packages/paddle/fluid/dygraph/layers.py", line 915, in _dygraph_call_func
    outputs = self.forward(*inputs, **kwargs)
  File "/root/autodl-tmp/Restormer_Paddle-main/models/archs/NBNet.py", line 53, in forward
    Projection = paddle.bmm(paddle.bmm(V, Vinverse), Vtrans)
  File "/root/miniconda3/lib/python3.8/site-packages/paddle/tensor/linalg.py", line 1413, in bmm
    return _C_ops.bmm(x, y)
SystemError: (Fatal) Operator bmm raises an paddle::memory::allocation::BadAlloc exception.
The exception content is
:ResourceExhaustedError: 

Out of memory error on GPU 0. Cannot allocate 16.000000GB memory on GPU 0, 17.868896GB memory has been allocated and available memory is only 5.818909GB.

Please check whether there is any other process using GPU 0.
1. If yes, please stop them, or start PaddlePaddle on another GPU.
2. If no, please decrease the batch size of your model. 
If the above ways do not solve the out of memory problem, you can try to use CUDA managed memory. The command is `export FLAGS_use_cuda_managed_memory=false`.
 (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:87)
. (at /paddle/paddle/fluid/imperative/tracer.cc:307)


