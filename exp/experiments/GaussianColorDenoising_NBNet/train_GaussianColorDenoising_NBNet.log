2023-06-10 16:28:27,148 INFO: 
  name: GaussianColorDenoising_NBNet
  model_type: ImageCleanModel
  scale: 1
  num_gpu: 1
  manual_seed: 100
  datasets:[
    train:[
      name: TrainSet
      type: Dataset_GaussianDenoising
      sigma_type: random
      sigma_range: [0, 50]
      in_ch: 3
      dataroot_gt: /root/autodl-tmp/SIDD/data/SIDD_patches/train/groundtruth
      dataroot_lq: none
      geometric_augs: True
      filename_tmpl: {}
      io_backend:[
        type: disk
      ]
      use_shuffle: True
      num_worker_per_gpu: 8
      batch_size_per_gpu: 4
      mini_batch_sizes: [8, 5, 4, 2, 1, 1]
      iters: [184000, 128000, 96000, 72000, 72000, 48000]
      gt_size: 384
      gt_sizes: [128, 160, 192, 256, 320, 384]
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 1
    ]
    val:[
      name: ValSet
      type: Dataset_GaussianDenoising
      sigma_test: 15
      in_ch: 3
      dataroot_gt: /root/autodl-tmp/CBSD68-dataset-master/CBSD68/original_png
      dataroot_lq: none
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 1
    ]
  ]
  network_g:[
    type: NBNet
  ]
  path:[
    pretrain_network_G: /root/autodl-tmp/Restormer_Paddle-main/output/model/last_model.pdparams
    strict_load_g: True
    resume_state: /root/autodl-tmp/Restormer_Paddle-main/output/model/last_model.pdopt
    output: /root/autodl-tmp/Restormer_Paddle-main/exp/
    root: /root/autodl-tmp
    experiments_root: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet
    models: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/models
    training_states: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/training_states
    log: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet
    visualization: /root/autodl-tmp/Restormer_Paddle-main/exp/experiments/GaussianColorDenoising_NBNet/visualization
  ]
  train:[
    total_iter: 1000000
    warmup_iter: -1
    use_grad_clip: True
    scheduler:[
      type: CosineAnnealingRestartCyclicLR
      learning_rate: 0.00015
      periods: [184000, 416000]
      restart_weights: [1, 1]
      eta_mins: [0.00015, 1e-06]
    ]
    mixing_augs:[
      mixup: True
      mixup_beta: 1.2
      use_identity: True
    ]
    optim_g:[
      type: AdamW
      weight_decay: 0.0001
      beta1: 0.9
      beta2: 0.999
    ]
    pixel_opt:[
      type: L1Loss
      loss_weight: 1
      reduction: mean
    ]
  ]
  val:[
    window_size: 8
    val_freq: 4000.0
    save_img: False
    rgb2bgr: True
    use_image: False
    max_minibatch: 8
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 0
        test_y_channel: False
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: False
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  is_train: True
  dist: False
  rank: 0
  world_size: 1

2023-06-10 16:28:27,228 INFO: Network: NBNet, with parameters: 10,455,235
2023-06-10 16:28:27,228 INFO: NBNet(
  (ConvBlock1): ConvBlock(
    (block): Sequential(
      (0): Conv2D(3, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(3, 32, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool1): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip1): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (2): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
    (3): ConvBlock(
      (block): Sequential(
        (0): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(32, 32, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa1): SSA(
    (conv1): Conv2D(64, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(64, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock2): ConvBlock(
    (block): Sequential(
      (0): Conv2D(32, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(32, 64, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool2): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip2): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
    (2): ConvBlock(
      (block): Sequential(
        (0): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa2): SSA(
    (conv1): Conv2D(128, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(128, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock3): ConvBlock(
    (block): Sequential(
      (0): Conv2D(64, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(64, 128, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool3): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip3): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(128, 128, kernel_size=[1, 1], data_format=NCHW)
    )
    (1): ConvBlock(
      (block): Sequential(
        (0): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(128, 128, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa3): SSA(
    (conv1): Conv2D(256, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(256, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock4): ConvBlock(
    (block): Sequential(
      (0): Conv2D(128, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(128, 256, kernel_size=[1, 1], data_format=NCHW)
  )
  (pool4): MaxPool2D(kernel_size=2, stride=None, padding=0)
  (skip4): Sequential(
    (0): ConvBlock(
      (block): Sequential(
        (0): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (1): LeakyReLU(negative_slope=0.01)
        (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
        (3): LeakyReLU(negative_slope=0.01)
      )
      (conv11): Conv2D(256, 256, kernel_size=[1, 1], data_format=NCHW)
    )
  )
  (ssa4): SSA(
    (conv1): Conv2D(512, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu1): LeakyReLU(negative_slope=0.01)
    (conv2): Conv2D(16, 16, kernel_size=[3, 3], padding=1, data_format=NCHW)
    (relu2): LeakyReLU(negative_slope=0.01)
    (conv11): Conv2D(512, 16, kernel_size=[1, 1], data_format=NCHW)
  )
  (ConvBlock5): ConvBlock(
    (block): Sequential(
      (0): Conv2D(256, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(256, 512, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv6): Conv2DTranspose(512, 256, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock6): ConvBlock(
    (block): Sequential(
      (0): Conv2D(512, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv7): Conv2DTranspose(256, 128, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock7): ConvBlock(
    (block): Sequential(
      (0): Conv2D(256, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv8): Conv2DTranspose(128, 64, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock8): ConvBlock(
    (block): Sequential(
      (0): Conv2D(128, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(128, 64, kernel_size=[1, 1], data_format=NCHW)
  )
  (upv9): Conv2DTranspose(64, 32, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)
  (ConvBlock9): ConvBlock(
    (block): Sequential(
      (0): Conv2D(64, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Conv2D(32, 32, kernel_size=[3, 3], padding=1, data_format=NCHW)
      (3): LeakyReLU(negative_slope=0.01)
    )
    (conv11): Conv2D(64, 32, kernel_size=[1, 1], data_format=NCHW)
  )
  (conv10): Conv2D(32, 3, kernel_size=[3, 3], padding=1, data_format=NCHW)
)
2023-06-10 16:28:27,323 INFO: Training statistics:
	Number of train images: 96000
	Dataset enlarge ratio: 1
	Batch size per gpu: 4
	World size (gpu number): 1
	Require iter number per epoch: 24000
	Total epochs: 42; iters: 1000000.
2023-06-10 16:28:27,323 INFO: Number of val images/folders in ValSet: 68
